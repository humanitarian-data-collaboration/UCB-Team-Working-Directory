{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.hdx_configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "Configuration.create(hdx_site='prod', user_agent='A_Quick_Example', hdx_read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the dataset has at least 1 resource of the required file type(s).\n",
    "\n",
    "def check_type(dataset, file_types=[]):\n",
    "    temp_dataset = Dataset.read_from_hdx(dataset)\n",
    "    temp_dataset.separate_resources()\n",
    "    if (len(temp_dataset.resources) > 0):\n",
    "        if (len(file_types) > 0):\n",
    "            if (not set(temp_dataset.get_filetypes()).isdisjoint(file_types)): \n",
    "                    return True\n",
    "        else :\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset is tagged with HXL tag, not provided by HXL\n",
    "\n",
    "def check_organization(dataset):\n",
    "    if dataset.get_organization()['title'] != 'Humanitarian Exchange Language(HXL)':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download one dataset with certain type(s), read it into Dataframe, \n",
    "# add all headers, tags and dataset names to our DataFrame,\n",
    "# and delete the dataset\n",
    "\n",
    "def process_dataset(dataset, file_type, dataframe, download_path, index):\n",
    "    global count\n",
    "# Download one dataset and read it into a DataFrame \n",
    "    if (file_type == None):\n",
    "        url, path = dataset_1.resources[0].download(download_path)\n",
    "        pandas_dataset = pd.read_csv(path)\n",
    "    else:\n",
    "        if (file_type not in dataset.get_filetypes()):\n",
    "            return 'Error: Required file type not in dataset OR dataset does not contain any resources.'\n",
    "        try:\n",
    "            url, path = dataset.resources[dataset.get_filetypes().index(file_type)].download(download_path)\n",
    "            print('Resource URL %s downloaded to %s' % (url, path))\n",
    "            pandas_dataset = pd.read_csv(path, encoding='latin-1')\n",
    "        except:\n",
    "            return 'Unknown error.'\n",
    "     \n",
    "    if \"HXL\" in os.path.basename(path) or \"hxl\" in os.path.basename(path):\n",
    "        return\n",
    "    dataset_df = pandas_dataset.head()\n",
    "    \n",
    "# Add headers and tags to our DataFrame\n",
    "    if len(dataset_df) > 2:\n",
    "        headers = list(dataset_df.columns.values)\n",
    "        tags = list(dataset_df.iloc[0,:])\n",
    "        for i in range(len(headers)):\n",
    "            try:\n",
    "                dic = {'Header': headers[i], 'Tag': tags[i], 'Dataset_name': os.path.basename(path), 'Index': index}\n",
    "                headers_and_tags.loc[len(headers_and_tags)] = dic\n",
    "            except:\n",
    "                print(\"Error: different number of headers and tags\")\n",
    "        count += 1\n",
    "    os.remove(path)\n",
    "    print(\"File Removed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all datasets with HXL tags\n",
    "\n",
    "datasets_HXL = Dataset.search_in_hdx('HXL')\n",
    "len(datasets_HXL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for all headers and tags\n",
    "\n",
    "col_names = ['Header', 'Tag', 'Dataset_name', 'Index']\n",
    "headers_and_tags= pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a temp DataFrame\n",
    "\n",
    "col_names = ['Header', 'Tag', 'Dataset_name', 'Index']\n",
    "temp = pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the template for replicating the processing function multiple times\n",
    "#for i in range(1000):\n",
    "    #process_dataset(datasets_HXL[i], 'CSV', headers_and_tags, './datasets', count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_HXL_2 = datasets_HXL[1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 665\n",
    "for i in range(len(datasets_HXL_2)):\n",
    "    process_dataset(datasets_HXL_2[i], 'CSV', temp, 'HDX File Holder', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_and_tags.to_excel(\"headerandtag.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxl_file = pd.read_excel(\"headerandtag.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxl_group1 = hxl_file.groupby(by=['Tag']).count().drop(columns=['Unnamed: 0','Dataset_name','Index']).sort_values(by=['Header'],ascending=False)\n",
    "hxl_group2 = hxl_file.groupby(['Tag'])['Header'].apply(lambda tags: ','.join(tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splits HXL Tags into Tags and additional attributes\n",
    "def splitter_tag(string):\n",
    "    return string.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_column = hxl_file['Tag']\n",
    "stringed = tag_column.apply(str)\n",
    "splitted_tag = stringed.apply(splitter_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_only = [i[0] for i in splitted_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives a count in descending order of only the HXL Tags in the Dataset\n",
    "hxl_file['Tags']= tags_only\n",
    "hxl_tag_count = hxl_file.drop(columns=['Unnamed: 0','Tag','Dataset_name','Index']).groupby(['Tags']).count().sort_values(by='Header',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groups the Headers by the Tags they are associated with\n",
    "headers_by_tag = hxl_file.groupby(['Tags'])['Header'].apply(lambda headers: ','.join(headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads the above as a CSV\n",
    "headers_by_tag.to_csv('headers_by_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
