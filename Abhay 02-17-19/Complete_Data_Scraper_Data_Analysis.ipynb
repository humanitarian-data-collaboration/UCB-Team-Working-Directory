{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.hdx_configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "Configuration.create(hdx_site='prod', user_agent='A_Quick_Example', hdx_read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the dataset has at least 1 resource of the required file type(s).\n",
    "\n",
    "def check_type(dataset, file_types=[]):\n",
    "    temp_dataset = Dataset.read_from_hdx(dataset)\n",
    "    temp_dataset.separate_resources()\n",
    "    if (len(temp_dataset.resources) > 0):\n",
    "        if (len(file_types) > 0):\n",
    "            if (not set(temp_dataset.get_filetypes()).isdisjoint(file_types)): \n",
    "                    return True\n",
    "        else :\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset is tagged with HXL tag, not provided by HXL\n",
    "\n",
    "def check_organization(dataset):\n",
    "    if dataset.get_organization()['title'] != 'Humanitarian Exchange Language(HXL)':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download one dataset with certain type(s), read it into Dataframe, \n",
    "# add all headers, tags and dataset names to our DataFrame,\n",
    "# and delete the dataset\n",
    "\n",
    "def process_dataset_2(dataset, file_type, dataframe, download_path, index, row_limit = 10):\n",
    "    global count\n",
    "# Download one dataset and read it into a DataFrame \n",
    "    if (file_type == None):\n",
    "        url, path = dataset_1.resources[0].download(download_path)\n",
    "        pandas_dataset = pd.read_csv(path)\n",
    "    else:\n",
    "        if (file_type not in dataset.get_filetypes()):\n",
    "            return 'Error: Required file type not in dataset OR dataset does not contain any resources.'\n",
    "        try:\n",
    "            url, path = dataset.resources[dataset.get_filetypes().index(file_type)].download(download_path)\n",
    "            print('Resource URL %s downloaded to %s' % (url, path))\n",
    "            pandas_dataset = pd.read_csv(path, encoding='latin-1')\n",
    "            pandas_dataset = pandas_dataset.head(row_limit)\n",
    "        except:\n",
    "            return 'Unknown error.'\n",
    "     \n",
    "    #if \"HXL\" in os.path.basename(path) or \"hxl\" in os.path.basename(path):\n",
    "        #return dataset_df\n",
    "    \n",
    "# Add headers, tags and data to our DataFrame if current dataset not empty\n",
    "        if (not pandas_dataset.empty):\n",
    "            dataset_df = pandas_dataset\n",
    "            headers = list(dataset_df.columns.values)\n",
    "            tags = list(dataset_df.iloc[0,:])\n",
    "            for i in range(len(headers)):\n",
    "                try:\n",
    "                    dic = {'Header': headers[i], 'Tag': tags[i], 'Data': list(dataset_df.iloc[1:, i]), \n",
    "                           'Relative Column Position': (i+1) / len(dataset_df.columns), \n",
    "                           'Dataset_name': os.path.basename(path), 'Index': index}\n",
    "                    headers_and_tags.loc[len(headers_and_tags)] = dic\n",
    "                except:\n",
    "                    print(\"Error: different number of headers and tags\")\n",
    "            count += 1\n",
    "        os.remove(path)\n",
    "        print(\"File Removed!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all datasets with HXL tags\n",
    "\n",
    "datasets_HXL = Dataset.search_in_hdx('HXL')\n",
    "len(datasets_HXL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for all headers and tags\n",
    "\n",
    "col_names = ['Header', 'Tag', 'Data','Relative Column Position','Dataset_name', 'Index']\n",
    "headers_and_tags= pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(300):\n",
    "    process_dataset_2(datasets_HXL[i], 'CSV', headers_and_tags, 'HDX File Holder', count)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_and_tags.to_csv(\"headerandtag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "headers_and_tags_f = pd.read_csv('headerandtag.csv')\n",
    "new_data = headers_and_tags_f['Data'].replace(\"'\",'',regex=True).replace('\\[','',regex=True).replace('\\]','',regex=True).str.split(\",\")\n",
    "headers_and_tags_f['Data'] = new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splits HXL Tags into Tags and additional attributes\n",
    "def splitter_tag(string):\n",
    "    return string.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_column = headers_and_tags_f['Tag']\n",
    "stringed = tag_column.apply(str)\n",
    "splitted_tag = stringed.apply(splitter_tag)\n",
    "tags_only = [i[0] for i in splitted_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_and_tags_f['Tag']= tags_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives a count in descending order of only the HXL Tags in the Dataset\n",
    "hxl_tag_count = headers_and_tags_f.drop(columns=['Unnamed: 0','Data','Relative Column Position','Dataset_name','Index']).groupby(['Tag']).count().sort_values(by='Header',ascending=False)\n",
    "#hxl_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groups the Headers by the Tags they are associated with\n",
    "headers_by_tag = headers_and_tags_f.groupby(['Tag'])['Header'].apply(lambda headers: ','.join(headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cash = headers_and_tags_f.drop(columns=['Unnamed: 0','Header','Relative Column Position','Dataset_name','Index']).groupby(['Tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "data_by_tag = headers_and_tags_f.groupby(['Tag'])['Data'].apply(list)\n",
    "data_by_tag = pd.DataFrame(data_by_tag)\n",
    "data_by_tag = data_by_tag['Data'].apply(lambda x:list(itertools.chain.from_iterable(x)))\n",
    "data_by_tag.to_csv('data_by_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
